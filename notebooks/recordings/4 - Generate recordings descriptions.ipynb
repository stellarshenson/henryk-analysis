{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936bf288-0839-469f-801b-7f7d029f254b",
   "metadata": {},
   "source": [
    "# Generate Recordings Descriptions\n",
    "This service will use ChatGPT to read the recordings transcriptions and will generate meaningful description for every recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5095c081-61c1-4495-ba51-846aa12c2378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:46:32.461344Z",
     "iopub.status.busy": "2024-05-08T13:46:32.461161Z",
     "iopub.status.idle": "2024-05-08T13:46:32.481767Z",
     "shell.execute_reply": "2024-05-08T13:46:32.480426Z",
     "shell.execute_reply.started": "2024-05-08T13:46:32.461331Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b557c6-c6ed-4c9c-bb72-60b1256a6003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:58:01.669394Z",
     "iopub.status.busy": "2024-05-08T13:58:01.669146Z",
     "iopub.status.idle": "2024-05-08T13:58:02.228735Z",
     "shell.execute_reply": "2024-05-08T13:58:02.227809Z",
     "shell.execute_reply.started": "2024-05-08T13:58:01.669381Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import anthropic\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from lib_henryk.config import *\n",
    "from lib_henryk.logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8830692-5768-41d1-a831-8121746d079d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:46:32.808223Z",
     "iopub.status.busy": "2024-05-08T13:46:32.808022Z",
     "iopub.status.idle": "2024-05-08T13:46:32.832483Z",
     "shell.execute_reply": "2024-05-08T13:46:32.831655Z",
     "shell.execute_reply.started": "2024-05-08T13:46:32.808211Z"
    }
   },
   "outputs": [],
   "source": [
    "# load api keys\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Your OpenAI API key\n",
    "api_key = os.getenv('CLAUDE_API_KEY')\n",
    "\n",
    "WEBHOOKS_TOKEN_ID = '2660666c-d957-4485-9a95-5e264563a022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47c7fb-4def-4e0c-9eb9-08f7d213fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(FILE_TRANSCRIPTION_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e5f9b66-b8b7-4dc6-9fa4-19021625b635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:57:08.259481Z",
     "iopub.status.busy": "2024-05-08T13:57:08.259242Z",
     "iopub.status.idle": "2024-05-08T13:57:08.313477Z",
     "shell.execute_reply": "2024-05-08T13:57:08.312548Z",
     "shell.execute_reply.started": "2024-05-08T13:57:08.259467Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required arguments; Expected either ('max_tokens', 'messages' and 'model') or ('max_tokens', 'messages', 'model' and 'stream') arguments to be given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set up the Anthropic API client\u001b[39;00m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m anthropic\u001b[38;5;241m.\u001b[39mClient(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[0;32m----> 4\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-3-opus-20240229\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJesteś ojcem małego Henryczka\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(message\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/anthropic/_utils/_utils.py:276\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Missing required arguments; Expected either ('max_tokens', 'messages' and 'model') or ('max_tokens', 'messages', 'model' and 'stream') arguments to be given"
     ]
    }
   ],
   "source": [
    "# Set up the Anthropic API client\n",
    "client = anthropic.Client(api_key=api_key)\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.3,\n",
    "    system=\"Jesteś ojcem małego Henryczka\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How are you today?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b834d1-ef10-4982-93d5-ce6d2dba253f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:54:06.561906Z",
     "iopub.status.busy": "2024-05-08T13:54:06.561123Z",
     "iopub.status.idle": "2024-05-08T13:54:06.570802Z",
     "shell.execute_reply": "2024-05-08T13:54:06.570246Z",
     "shell.execute_reply.started": "2024-05-08T13:54:06.561886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*clears throat and speaks in a croaky voice* Hmm, well I am today, young Padawan. The Force, strong in me it flows. Yes, heh heh heh.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c3558-4790-4f10-b19b-ac6f398cc066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
